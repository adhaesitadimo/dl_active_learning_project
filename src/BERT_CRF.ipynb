{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-CRF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_HtpxFuY9bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install allennlp==1.0.0rc5\n",
        "#!pip install allennlp-models==1.0.0rc5\n",
        "#!pip freeze | grep allennlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tmrGBkLne6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    cuda_device = 0\n",
        "else:\n",
        "    cuda_device = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHBbKpyQyO7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.data.dataset_readers import Conll2003DatasetReader\n",
        "from allennlp.data.token_indexers import PretrainedTransformerMismatchedIndexer\n",
        "from allennlp.data.vocabulary import Vocabulary\n",
        "\n",
        "BERT_MODEL = 'bert-base-cased'\n",
        "indexer = PretrainedTransformerMismatchedIndexer(model_name=BERT_MODEL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BdjfOzgewoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Dict, List, Sequence, Iterable\n",
        "import itertools\n",
        "import logging\n",
        "\n",
        "from overrides import overrides\n",
        "\n",
        "from allennlp.common.checks import ConfigurationError\n",
        "from allennlp.common.file_utils import cached_path\n",
        "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
        "from allennlp.data.dataset_readers.dataset_utils import to_bioul\n",
        "from allennlp.data.fields import TextField, SequenceLabelField, Field, MetadataField\n",
        "from allennlp.data.instance import Instance\n",
        "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
        "from allennlp.data.tokenizers import Token\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def _is_divider(line: str) -> bool:\n",
        "    empty_line = line.strip() == \"\"\n",
        "    if empty_line:\n",
        "        return True\n",
        "    else:\n",
        "        first_token = line.split()[0]\n",
        "        if first_token == \"-DOCSTART-\":\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "class GeniaDatasetReader(Conll2003DatasetReader):\n",
        "\n",
        "    def _read(self, file_path: str) -> Iterable[Instance]:\n",
        "        # if `file_path` is a URL, redirect to the cache\n",
        "        file_path = cached_path(file_path)\n",
        "\n",
        "        with open(file_path, \"r\") as data_file:\n",
        "            logger.info(\"Reading instances from lines in file at: %s\", file_path)\n",
        "\n",
        "            # Group into alternative divider / sentence chunks.\n",
        "            for is_divider, lines in itertools.groupby(data_file, _is_divider):\n",
        "                # Ignore the divider chunks, so that `lines` corresponds to the words\n",
        "                # of a single sentence.\n",
        "                if not is_divider:\n",
        "                    fields = [line.strip().split() for line in lines]\n",
        "                    # unzipping trick returns tuples, but our Fields need lists\n",
        "                    fields = [list(field) for field in zip(*fields)]\n",
        "                    tokens_, ner_tags = fields\n",
        "                    # TextField requires `Token` objects\n",
        "                    tokens = [Token(token) for token in tokens_]\n",
        "\n",
        "                    yield self.text_to_instance(tokens, ner_tags)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGiy23kVqVl3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e5ea5fcf-11af-4538-f51a-c2b7e5c5e720"
      },
      "source": [
        "dataset_type = 'conll'\n",
        "\n",
        "if dataset_type == 'conll':\n",
        "  reader = Conll2003DatasetReader(token_indexers={'tokens': indexer})\n",
        "  train_dataset = reader.read('train.txt')\n",
        "  dev_dataset = reader.read('test.txt')\n",
        "elif dataset_type == 'genia':\n",
        "  reader = GeniaDatasetReader(token_indexers={'tokens': indexer})\n",
        "  train_dataset = reader.read('./Genia4ERtask1.iob2')\n",
        "  dev_dataset = reader.read('./Genia4EReval1.iob2')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14041it [00:01, 10837.25it/s]\n",
            "3453it [00:00, 8314.39it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EgN5HY43FLV",
        "colab_type": "code",
        "outputId": "9068b028-221c-469d-8e3b-7421b1d87ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab = Vocabulary.from_instances(train_dataset.instances)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 14041/14041 [00:00<00:00, 109655.47it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKP3pzv02mbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset.index_with(vocab)\n",
        "dev_dataset.index_with(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzhhreoxy9vI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.modules.token_embedders import PretrainedTransformerMismatchedEmbedder\n",
        "\n",
        "embedder = PretrainedTransformerMismatchedEmbedder(model_name=BERT_MODEL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfIZLbQkzOjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.modules.text_field_embedders import BasicTextFieldEmbedder\n",
        "\n",
        "text_field_embedder = BasicTextFieldEmbedder({'tokens': embedder})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rshMUAr-zVo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.models import SimpleTagger\n",
        "from allennlp.modules.seq2seq_encoders import PassThroughEncoder\n",
        "from allennlp_models.tagging import CrfTagger\n",
        "\n",
        "seq2seq_encoder = PassThroughEncoder(input_dim=embedder.get_output_dim())\n",
        "\n",
        "tagger = CrfTagger( text_field_embedder=text_field_embedder, \n",
        "                      vocab=vocab, \n",
        "                      encoder=seq2seq_encoder,\n",
        "                      calculate_span_f1=True,\n",
        "                      label_encoding='IOB1',\n",
        "\n",
        "                      dropout = 0.2).cuda(device=cuda_device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoQKuvLoz24X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e0838f35-419c-42ed-8dbb-1c6dac6e1eef"
      },
      "source": [
        "import torch.optim as optim\n",
        "from allennlp.training.learning_rate_schedulers import ReduceOnPlateauLearningRateScheduler\n",
        "\n",
        "from allennlp.data.dataloader import DataLoader\n",
        "from allennlp.training import GradientDescentTrainer\n",
        "\n",
        "NUM_EPOCHS = 1\n",
        "N_MICRO_BATCH = 1\n",
        "\n",
        "optimizer = optim.Adam(tagger.parameters(), lr=1e-5)\n",
        "train_data_loader = DataLoader(dataset=train_dataset, batch_size=32)\n",
        "val_data_loader = DataLoader(dataset=dev_dataset, batch_size=100)\n",
        "lr_scheduler = ReduceOnPlateauLearningRateScheduler(optimizer, patience=1)\n",
        "\n",
        "\n",
        "trainer = GradientDescentTrainer(\n",
        "    model=tagger,\n",
        "    optimizer=optimizer,\n",
        "    data_loader=train_data_loader,\n",
        "    validation_data_loader=val_data_loader,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    cuda_device=cuda_device,\n",
        "    learning_rate_scheduler=lr_scheduler,\n",
        "    patience=5,\n",
        "    num_gradient_accumulation_steps=N_MICRO_BATCH)\n",
        "\n",
        "metrics = trainer.train()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.9295, accuracy3: 0.9738, precision-overall: 0.6855, recall-overall: 0.6373, f1-measure-overall: 0.6606, loss: 110.1791, reg_loss: 0.0000 ||: 100%|██████████| 439/439 [05:09<00:00,  1.42it/s]\n",
            "accuracy: 0.9772, accuracy3: 0.9928, precision-overall: 0.8656, recall-overall: 0.8780, f1-measure-overall: 0.8718, loss: 107.6890, reg_loss: 0.0000 ||: 100%|██████████| 35/35 [00:37<00:00,  1.07s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXq255RWSjSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.predictors import SentenceTaggerPredictor\n",
        "import numpy as np\n",
        "from seqeval.metrics import f1_score\n",
        "\n",
        "def predict_from_instance(model, reader, data, evaluate = False):\n",
        "  predictor = SentenceTaggerPredictor(model, reader)\n",
        "  predictions = []\n",
        "  scores = []\n",
        "  len_sentence = data['tokens'].sequence_length()\n",
        "  text = [data['tokens'].tokens[j].text for j in range(len_sentence)]\n",
        "  tag_logits = predictor.predict(' '.join(text))['logits']\n",
        "\n",
        "  tag_ids = np.argmax(tag_logits, axis=-1)\n",
        "  res = [tagger.vocab.get_token_from_index(i, 'labels') for i in tag_ids]\n",
        "  if evaluate:\n",
        "    score = f1_score(res, data['tags'].labels)\n",
        "  return {'predicted_tags': res,'f1-score': score} "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}