{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections, pandas as pd, numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from libact.query_strategies import UncertaintySampling, RandomSampling\n",
    "# from active_learning_seq import RandomSamplingWithRetraining\n",
    "import torch\n",
    "\n",
    "from actleto import ActiveLearner, ActiveLearnerUiWidget, make_libact_strategy_ctor\n",
    "from actleto.annotator.visualizers.seq_annotation import SeqAnnotationVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 13:52:02,005 Reading data from ../../../data/fib\n",
      "2020-06-07 13:52:02,006 Train: ../../../data/fib/train.txt\n",
      "2020-06-07 13:52:02,006 Dev: ../../../data/fib/dev.txt\n",
      "2020-06-07 13:52:02,007 Test: ../../../data/fib/test.txt\n",
      "Tags: ['fib']\n",
      "I've corrected 13 errors in train dataset\n",
      "I've corrected 4 errors in test dataset\n"
     ]
    }
   ],
   "source": [
    "from flair.datasets import ColumnCorpus\n",
    "from model_wrappers import find_in_between, convert_y_to_bio_format\n",
    "from bert_sequence_tagger.bert_utils import make_bert_tag_dict_from_flair_corpus\n",
    "from libact_bert_creator import prepare_corpus\n",
    "from utils_data import create_helper, convert_y_to_dict_format\n",
    "import random\n",
    "\n",
    "diagnosis = 'fib'\n",
    "\n",
    "data_folder = '../../../data/' + diagnosis\n",
    "corpus = ColumnCorpus(data_folder, {0 : 'text', 1 : 'ner'},\n",
    "                                train_file='train.txt',\n",
    "                                test_file='test.txt',\n",
    "                                dev_file='dev.txt') # We do not need dev set\n",
    "\n",
    "# Creating tag dictionaries\n",
    "idx2tag, tag2idx = make_bert_tag_dict_from_flair_corpus(corpus)\n",
    "tags = list(set((tag.split('-')[1] for tag in idx2tag if len(tag.split('-')) > 1)))\n",
    "print('Tags:', tags)\n",
    "\n",
    "\n",
    "# Convert into the format suitable for training\n",
    "X_train, y_train = prepare_corpus(corpus.train)\n",
    "X_test, y_test = prepare_corpus(corpus.test)\n",
    "\n",
    "# Shuffle X_train and y_train\n",
    "\n",
    "def check_first_I_error(data, name):\n",
    "    counter = 0\n",
    "    for seq in data:\n",
    "        if seq[0]=='I-'+diagnosis:\n",
    "            seq[0] = 'B-'+diagnosis\n",
    "            counter+=1\n",
    "        for i in range(1, len(seq)):\n",
    "            if seq[i-1]=='O' and seq[i]=='I-'+diagnosis:\n",
    "                seq[i] = 'B-'+diagnosis\n",
    "                counter+=1\n",
    "    print(\"I've corrected\", counter, \"errors in\", name, \"dataset\" )\n",
    "    return data\n",
    "\n",
    "y_train = check_first_I_error(y_train, 'train')\n",
    "y_test = check_first_I_error(y_test, 'test')\n",
    "    \n",
    "\n",
    "# Convert into the format suitable for visualization\n",
    "y_train_dict = convert_y_to_dict_format(X_train, y_train)\n",
    "X_helper = create_helper(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8936"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create seeding examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of seed examples 125\n"
     ]
    }
   ],
   "source": [
    "from utils_data import sample_seed_elements_for_al\n",
    "\n",
    "\n",
    "y_seed_dict = sample_seed_elements_for_al(y_train_dict, negative_size=100, \n",
    "                                          positive_size=25, random_seed=123)\n",
    "\n",
    "print('Number of seed examples', len([e for e in y_seed_dict if e is not None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# [i for i in y_seed_dict if i is not None or not np.nan]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model and active learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe551888070>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "MAX_LEN = 100\n",
    "PRED_BATCH_SIZE = 500\n",
    "N_EPOCHS = 30\n",
    "\n",
    "N_SAMPLES_PER_AL_ITER = 30\n",
    "LEARNING_RATE = 5e-5\n",
    "VALIDATION_RATIO = 0.1\n",
    "\n",
    "PATIENCE = 1\n",
    "\n",
    "BERT_MODEL_TYPE = '../../../data/Ru_bert_model/'\n",
    "CACHE_DIR = '../../../cache_'+diagnosis+'/cache'\n",
    "\n",
    "RANDOM_STATE = 2019\n",
    "torch.manual_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading saved seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment this cell if you don't have saved seed\n",
    "# import numpy as np\n",
    "\n",
    "# y_seed_dict = np.load(CACHE_DIR+'.npy', allow_pickle=True).tolist()\n",
    "\n",
    "# for i in range(len(y_seed_dict)):\n",
    "#     if y_seed_dict[i] is not None:\n",
    "#         if 'None' in y_seed_dict[i]:\n",
    "#             y_seed_dict[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSamplingWithRetraining(RandomSampling):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.model = kwargs.pop('model', None)\n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.model.train(self.dataset)\n",
    "        \n",
    "    def update(self, indexes, labels):\n",
    "        self.model.train(self.dataset, indexes)\n",
    "\n",
    "    def make_query(self):\n",
    "        return super().make_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New indexes None\n",
      "X shape (125,)\n",
      "y shape (125,)\n",
      "Number of all training examples:  112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 6/30 [00:06<00:25,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "from libact_bert_creator import LibActBertCreator\n",
    "\n",
    "bert_creator = LibActBertCreator(idx2tag=idx2tag,\n",
    "                                 tag2idx=tag2idx,\n",
    "                                 tokenizer_name=BERT_MODEL_TYPE, \n",
    "                                 bert_model_type=BERT_MODEL_TYPE,\n",
    "                                 cache_dir=CACHE_DIR,\n",
    "                                 n_epochs=N_EPOCHS,\n",
    "                                 lr=LEARNING_RATE,\n",
    "                                 bs=BATCH_SIZE,\n",
    "                                 ebs=PRED_BATCH_SIZE,\n",
    "                                 patience=PATIENCE)\n",
    "\n",
    "\n",
    "\n",
    "# active_learn_alg_ctor = make_libact_strategy_ctor(lambda trn_ds: RandomSamplingWithRetraining(trn_ds, \n",
    "#                                                                                      model=bert_creator(\n",
    "#                                                                                          valid_ratio=VALIDATION_RATIO,\n",
    "#                                                                                          retrain_epochs=N_EPOCHS,\n",
    "#                                                                                          autofill_similar_objects=True,\n",
    "#                                                                                          n_upsample_positive=0.)\n",
    "#                                                                                     ),\n",
    "#                                                   max_samples_number=30)\n",
    "\n",
    "\n",
    "active_learn_alg_ctor = make_libact_strategy_ctor(lambda trn_ds: UncertaintySampling(trn_ds, \n",
    "                                                                                     model=bert_creator(\n",
    "                                                                                         valid_ratio=VALIDATION_RATIO,\n",
    "                                                                                         retrain_epochs=N_EPOCHS,\n",
    "                                                                                         autofill_similar_objects=True,\n",
    "                                                                                         n_upsample_positive=0.)\n",
    "                                                                                    ),\n",
    "                                                  max_samples_number=30)\n",
    "\n",
    "# Creating ActiveLearning object that implements AL logic.\n",
    "active_learner = ActiveLearner(active_learn_alg_ctor=active_learn_alg_ctor,\n",
    "                               X_full_dataset=X_helper.texts.tolist(),\n",
    "                               y_full_dataset=y_seed_dict,\n",
    "                               rnd_start_steps=0)\n",
    "\n",
    "active_learner.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating widget for annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb37de9dc224e1f91c1415285af0bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ActiveLearnerUiWidget(children=(HBox(children=(Button(description='Next iteration', style=ButtonStyle()), Labe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preliminary_path = CACHE_DIR\n",
    "# This try-catch block is needed to stop autosave thread in \n",
    "#case we invoke the cell multiple times.\n",
    "try:\n",
    "    if active_learn_ui:\n",
    "        active_learn_ui.stop()\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# Creaing the active learner widget itself and configure \n",
    "# it with active_learner, X_helper.\n",
    "active_learn_ui = ActiveLearnerUiWidget(active_learner=active_learner,\n",
    "                                        X_helper=X_helper,\n",
    "                                        display_feature_table=False,\n",
    "                                        drop_labels=[],\n",
    "                                        y_labels=None,\n",
    "                                        save_path=preliminary_path,\n",
    "                                        save_time=120, \n",
    "                                        visualizer=SeqAnnotationVisualizer(tags=tags))\n",
    "\n",
    "active_learn_ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "results_s = []\n",
    "precisions = []\n",
    "precisions_s = []\n",
    "recalls = []\n",
    "recalls_s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "running = 6\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_sequence_tagger.bert_utils import prepare_flair_corpus\n",
    "from bert_sequence_tagger.metrics import f1_entity_level, f1_token_level\n",
    "\n",
    "def get_seq_tagger(active_learner):\n",
    "    return active_learner._active_learn_algorithm._libact_query_alg.impl.model._model\n",
    "\n",
    "def func(list):\n",
    "    list_s = []\n",
    "    for i in list:\n",
    "        if 'B-'+diagnosis in i or 'I-'+diagnosis in i:\n",
    "            list_s.append(1)\n",
    "        else:\n",
    "            list_s.append(0)\n",
    "    return list_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: 0.7394957983193275 , precision: 0.6285714285714286 , recall: 0.8979591836734694\n",
      "--------\n",
      "like a classification problem\n",
      "F1_score: 0.8141592920353983 , precision: 0.7076923076923077 , recall: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score as f1_score_s\n",
    "from sklearn.metrics import precision_score as precision_score_s\n",
    "from sklearn.metrics import recall_score as recall_score_s\n",
    "\n",
    "seq_tagger = get_seq_tagger(active_learner)\n",
    "preds = seq_tagger.predict(X_test)[0]\n",
    "f1 = f1_score(y_test, preds)\n",
    "prec = precision_score(y_test, preds)\n",
    "rec = recall_score(y_test, preds)\n",
    "\n",
    "\n",
    "y_test_s = func(y_test)\n",
    "preds_s = func(preds)\n",
    "\n",
    "f1_s = f1_score_s(y_test_s, preds_s)\n",
    "prec_s = precision_score_s(y_test_s, preds_s)\n",
    "rec_s = recall_score_s(y_test_s, preds_s)\n",
    "\n",
    "\n",
    "print(f'F1_score: {f1} , precision: {prec} , recall: {rec}')\n",
    "print('--------\\nlike a classification problem')\n",
    "print(f'F1_score: {f1_s} , precision: {prec_s} , recall: {rec_s}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append(f1)\n",
    "results_s.append(f1_s)\n",
    "precisions.append(prec)\n",
    "precisions_s.append(prec_s)\n",
    "recalls.append(rec)\n",
    "recalls_s.append(rec_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score: [0.7394957983193275]\n",
      "precisions: [0.6285714285714286]\n",
      "recalls: [0.8979591836734694]\n",
      "-------------\n",
      "like a classification problem\n",
      "F1_score: [0.8141592920353983]\n",
      "precisions: [0.7076923076923077]\n",
      "recalls: [0.9583333333333334]\n"
     ]
    }
   ],
   "source": [
    "print('F1_score:', results)\n",
    "print('precisions:', precisions)\n",
    "print('recalls:', recalls)\n",
    "print('-------------\\nlike a classification problem')\n",
    "print('F1_score:', results_s)\n",
    "print('precisions:', precisions_s)\n",
    "print('recalls:', recalls_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(results, label='in sequence')\n",
    "plt.plot(results_s, label='classification')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_of_y_test = []\n",
    "array_of_preds = []\n",
    "array_of_x = []\n",
    "number_of_correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == preds[i]:\n",
    "        number_of_correct += 1\n",
    "        \n",
    "    else:\n",
    "        array_of_preds.append(preds[i])\n",
    "        array_of_y_test.append(y_test[i])\n",
    "        array_of_x.append(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/.pyenv/versions/3.7.4/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/.pyenv/versions/3.7.4/lib/python3.7/threading.py\", line 1178, in run\n",
      "    self.function(*self.args, **self.kwargs)\n",
      "  File \"/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/actleto/annotator/ui_widget.py\", line 116, in _save_on_timer\n",
      "    self._save_answers(os.path.splitext(self._save_path)[0] + '_autosave')\n",
      "  File \"/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/actleto/annotator/ui_widget.py\", line 190, in _save_answers\n",
      "    np.save(path, self._active_learner.get_annotation())\n",
      "  File \"<__array_function__ internals>\", line 6, in save\n",
      "  File \"/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/numpy/lib/npyio.py\", line 530, in save\n",
      "    fid = open(file, \"wb\")\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '../../../cache_fib/cache_autosave.npy'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# epoch = 13\n",
    "name_of_file = 'wrong_answers/'+ diagnosis + '/' + str(running) + '_' + str(epoch) + '_epoch_wrong_answers.txt'\n",
    "sample = open(name_of_file, 'w') \n",
    "print(\"correct answers:\", number_of_correct, file = sample)\n",
    "print(\"wrong answers:\", len(array_of_preds), file = sample)\n",
    "\n",
    "print(f'F1_score: {f1} , precision: {prec} , recall: {rec}', file = sample)\n",
    "print('--------\\nlike a classification problem', file = sample)\n",
    "print(f'F1_score: {f1_s} , precision: {prec_s} , recall: {rec_s}', file = sample)\n",
    "\n",
    "print(file = sample)\n",
    "\n",
    "for i_of_error in range(len (array_of_y_test)):\n",
    "    a_set = set(array_of_y_test[i_of_error]) \n",
    "    b_set = set(array_of_preds[i_of_error]) \n",
    "    if ('B-'+diagnosis in a_set or 'I-'+diagnosis in a_set) and ('B-'+diagnosis in b_set or 'I-'+diagnosis in b_set):\n",
    "        flag_of_class = '+++' \n",
    "    else: \n",
    "        flag_of_class = '---'\n",
    "    print('Text   ||Actual||Prediction', flag_of_class, file = sample)\n",
    "    for i in range(len (array_of_y_test[i_of_error])):\n",
    "        if array_of_y_test[i_of_error][i] != array_of_preds[i_of_error][i]:\n",
    "            print(array_of_x[i_of_error][i], \"  \", array_of_y_test[i_of_error][i], \"   \", array_of_preds[i_of_error][i], file = sample)\n",
    "\n",
    "    print(\"actual:\", array_of_y_test[i_of_error], file = sample)\n",
    "    print(\"pred:  \", array_of_preds[i_of_error], file = sample)\n",
    "    print(array_of_x[i_of_error], file = sample)\n",
    "    print(file = sample)\n",
    "print('F1_score:', results, file = sample)\n",
    "print('precisions:', precisions, file = sample)\n",
    "print('recalls:', recalls, file = sample)\n",
    "print('-------------\\nlike a classification problem', file = sample)\n",
    "print('F1_score:', results_s, file = sample)\n",
    "print('precisions:', precisions_s, file = sample)\n",
    "print('recalls:', recalls_s, file = sample)\n",
    "sample.close()\n",
    "epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You can turn on and off some features of AL and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learner._active_learn_algorithm._libact_query_alg.impl.model._self_training_samples = 0\n",
    "active_learner._active_learn_algorithm._libact_query_alg.impl.model._n_upsample_positive = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_learner._active_learn_algorithm._libact_query_alg.impl.model._n_upsample_positive = 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "012b7ff2636e4ff2929afd8230a6b225": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "02b7a355ee7445af818aa6a56f7ede0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2bddb62c7d014abe9a06da44227b9bc8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Save",
       "layout": "IPY_MODEL_fc95a1be1ebc4a56bca855d00efc2169",
       "style": "IPY_MODEL_7c2c262a63f5492c8fe5a2e2c442ad07"
      }
     },
     "2d171063d6af4a87a8b00ff7c33f2fbf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "33a300b6e38e47ea9869bc8309162378": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8271b9901a88424c9c29da89bcdcc866",
        "IPY_MODEL_db7c1844ff3946e29b51d200ab72a49c",
        "IPY_MODEL_ea3105f5013a4240abc562f92119415d"
       ],
       "layout": "IPY_MODEL_9841d6098a844ed8a14e1d42a0264a56"
      }
     },
     "3de00db997a343c1964215bd8c43de37": {
      "model_module": "text_selector",
      "model_module_version": "^0.0.0",
      "model_name": "TSWidgetModel",
      "state": {
       "_model_module_version": "^0.0.0",
       "_view_module_version": "^0.0.0",
       "layout": "IPY_MODEL_873d27630ace4c19bc4a04968fe137fd",
       "res": [
        "aaa"
       ],
       "tags": [
        "protein",
        "DNA",
        "cell_type",
        "cell_line",
        "RNA"
       ],
       "txts": [
        "As detected by in vivo footprinting , priming markedly increases the activation-dependent engagement of the P0 and P1 NFAT-binding elements of the IL-4 promoter .",
        "Binding parameters of [ 3H ] pyrilamine binding were Kd = 5.53 nM and Bmax = 2 , 647 sites/cell .",
        "PDBu-treated HL-60 cells remained viable for 7 days and thereafter began to die via apoptosis , with a concomitant down-regulation of Bcl-xL .",
        "Human RAR alpha was expressed in H9 , U937 and THP-1 cells , but almost undetectable in CEM cells .",
        "No increase in TGF-beta mRNA was observed ."
       ]
      }
     },
     "56a8c82dbbd04f2bba722806c440b1ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9cb589e8535b402ab4d031a1b1b68537",
        "IPY_MODEL_62c09e2fbc894017ad2f897bdac69f5a"
       ],
       "layout": "IPY_MODEL_02b7a355ee7445af818aa6a56f7ede0e"
      }
     },
     "6016917868fe4cfca53920851c30bcb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "62c09e2fbc894017ad2f897bdac69f5a": {
      "model_module": "text_selector",
      "model_module_version": "^0.0.0",
      "model_name": "TSWidgetModel",
      "state": {
       "_model_module_version": "^0.0.0",
       "_view_module_version": "^0.0.0",
       "layout": "IPY_MODEL_2d171063d6af4a87a8b00ff7c33f2fbf",
       "res": [
        "aaa"
       ],
       "tags": [
        "protein",
        "DNA",
        "cell_type",
        "cell_line",
        "RNA"
       ],
       "txts": [
        "As detected by in vivo footprinting , priming markedly increases the activation-dependent engagement of the P0 and P1 NFAT-binding elements of the IL-4 promoter .",
        "Binding parameters of [ 3H ] pyrilamine binding were Kd = 5.53 nM and Bmax = 2 , 647 sites/cell .",
        "PDBu-treated HL-60 cells remained viable for 7 days and thereafter began to die via apoptosis , with a concomitant down-regulation of Bcl-xL .",
        "Human RAR alpha was expressed in H9 , U937 and THP-1 cells , but almost undetectable in CEM cells .",
        "No increase in TGF-beta mRNA was observed ."
       ]
      }
     },
     "65e267fca04f48b2ae0463051495c272": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_ba06e045de7c49e99e82394a074f3c70",
       "style": "IPY_MODEL_012b7ff2636e4ff2929afd8230a6b225",
       "value": "Iteration#..."
      }
     },
     "6d20dd66e4c54515bd8630a4b5628255": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_33a300b6e38e47ea9869bc8309162378",
        "IPY_MODEL_3de00db997a343c1964215bd8c43de37"
       ],
       "layout": "IPY_MODEL_827111bd3e5f4004be5c8cdae33ec8ac"
      }
     },
     "7c2c262a63f5492c8fe5a2e2c442ad07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "827111bd3e5f4004be5c8cdae33ec8ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8271b9901a88424c9c29da89bcdcc866": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Next Iteration",
       "icon": "clock-o",
       "layout": "IPY_MODEL_eb638749231647e494aa80cf28b0c35a",
       "style": "IPY_MODEL_fcbfcb7a62ff44f1b44b6d6fd38075a8"
      }
     },
     "873d27630ace4c19bc4a04968fe137fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "87e6c275162b4a53bc940dba9c0044a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9841d6098a844ed8a14e1d42a0264a56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9cb589e8535b402ab4d031a1b1b68537": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_be788141dae8484bae65354f63c3c82b",
        "IPY_MODEL_65e267fca04f48b2ae0463051495c272",
        "IPY_MODEL_2bddb62c7d014abe9a06da44227b9bc8"
       ],
       "layout": "IPY_MODEL_87e6c275162b4a53bc940dba9c0044a5"
      }
     },
     "a42e2142f28a441bb37db5cc94ebaa24": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "ab5d55e09f8c4e669ad89bd0cdaf2bfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "ba06e045de7c49e99e82394a074f3c70": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bd4a12b7f207479297f136238950aba6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "be788141dae8484bae65354f63c3c82b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Next Iteration",
       "icon": "clock-o",
       "layout": "IPY_MODEL_fd4f46c9ddcd4084a024a34ee6217894",
       "style": "IPY_MODEL_ab5d55e09f8c4e669ad89bd0cdaf2bfe"
      }
     },
     "d30506af0b0a48adbfef87387a9fc956": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "db7c1844ff3946e29b51d200ab72a49c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_bd4a12b7f207479297f136238950aba6",
       "style": "IPY_MODEL_6016917868fe4cfca53920851c30bcb7",
       "value": "Iteration#..."
      }
     },
     "ea3105f5013a4240abc562f92119415d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "description": "Save",
       "layout": "IPY_MODEL_d30506af0b0a48adbfef87387a9fc956",
       "style": "IPY_MODEL_a42e2142f28a441bb37db5cc94ebaa24"
      }
     },
     "eb638749231647e494aa80cf28b0c35a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fc95a1be1ebc4a56bca855d00efc2169": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "fcbfcb7a62ff44f1b44b6d6fd38075a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "fd4f46c9ddcd4084a024a34ee6217894": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
